name: ETL Pipeline Simple

on:
  schedule:
    # Diario a las 8:00 AM UTC
    - cron: '0 8 * * *'
  workflow_dispatch:
  push:
    branches: [ main ]
    paths: ['flows/**', 'data/**']

jobs:
  etl-simple:
    runs-on: ubuntu-latest
    
    steps:
    - name: ğŸ”„ Checkout code
      uses: actions/checkout@v4
    
    - name: ğŸ Setup Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
        cache: 'pip'
    
    - name: ğŸ“¦ Install dependencies
      run: |
        pip install -r requirements.txt
    
    - name: ğŸ“¥ Download previous database
      uses: actions/download-artifact@v4
      with:
        name: etl-database
        path: data/
      continue-on-error: true  # No falla si no existe DB anterior
    
    - name: ğŸ” Check if database exists
      run: |
        if [ -f data/etl.db ]; then
          echo "âœ… Base de datos anterior encontrada"
          sqlite3 data/etl.db "SELECT COUNT(*) as total_runs FROM etl_monitor;" || echo "Tabla etl_monitor no existe aÃºn"
        else
          echo "â„¹ï¸ No hay base de datos anterior, se crearÃ¡ una nueva"
        fi
    
    - name: ğŸš€ Execute ETL Pipeline
      run: |
        echo "ğŸš€ Iniciando ETL Pipeline..."
        cd flows
        python etl_simple.py
        echo "âœ… Pipeline completado"
    
    - name: ğŸ“Š Show results
      run: |
        echo "ğŸ“Š Resultados del ETL:"
        ls -la data/
        if [ -f data/etl.log ]; then
          echo "ğŸ“ Ãšltimas lÃ­neas del log:"
          tail -20 data/etl.log
        fi
        if [ -f data/etl.db ]; then
          echo "ğŸ“ˆ Registros en etl_monitor:"
          sqlite3 data/etl.db "SELECT COUNT(*) as total_runs, MAX(run_ts) as last_run FROM etl_monitor;" || echo "Error consultando etl_monitor"
        fi
    
    - name: ğŸ’¾ Upload database (persistent)
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: etl-database
        path: data/etl.db
        if-no-files-found: ignore
        retention-days: 30           # MÃ¡s tiempo para la DB persistente
        compression-level: 6
    
    - name: ğŸ“ Upload execution results
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: etl-results-${{ github.run_number }}
        path: |
          data/etl.log
          data/df_final.csv
          data/raw_*.csv
          data/raw_*.json
          
        if-no-files-found: ignore
        retention-days: 7
        compression-level: 0  


